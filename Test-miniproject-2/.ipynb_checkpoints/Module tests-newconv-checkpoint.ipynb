{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70876e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from Miniproject_2.model import *\n",
    "\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.set_grad_enabled(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e546689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44e2c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(X, K, stride=1, padding=0, dilation=1):\n",
    "    N, _, H, W = X.shape\n",
    "    out_channels, in_channels, h, w = K.shape\n",
    "    assert X.shape[1] == in_channels\n",
    "    assert w == h\n",
    "    \n",
    "    h_out = int((H + 2*padding - dilation*(h-1)-1)/stride+1)\n",
    "    w_out = int((W + 2*padding - dilation*(w-1)-1)/stride+1)\n",
    "\n",
    "    Xprime  = unfold(X, kernel_size=h, padding=padding, dilation=dilation, stride=stride)\n",
    "    cΠks, L = Xprime.shape[1], Xprime.shape[2]\n",
    "    Xprime  = torch.transpose(Xprime, 1, 2).reshape(-1, cΠks)\n",
    "\n",
    "    Kprime  = K.reshape(out_channels, cΠks)\n",
    "    \n",
    "    Yprime = Xprime @ Kprime.t()    \n",
    "    Y = Yprime.reshape(N, L, out_channels).transpose_(1, 2)\n",
    "    Y = fold(Y, output_size=[h_out, w_out], kernel_size=1, padding=0, dilation=1, stride=1)\n",
    "    return Y\n",
    "\n",
    "\n",
    "def conv_transpose2d(Y, K, stride=1, padding=0, dilation=1):\n",
    "    N, _, H, W = Y.shape\n",
    "    out_channels, in_channels, h, w = K.shape\n",
    "    assert Y.shape[1] == out_channels\n",
    "    assert w == h\n",
    "    \n",
    "    h_out = (H-1)*stride - 2*padding + dilation*(h-1) + 1\n",
    "    w_out = (W-1)*stride - 2*padding + dilation*(w-1) + 1\n",
    "\n",
    "    Yprime = Y.flatten(-2,-1)\n",
    "    Yprime = Yprime.transpose_(1, 2).flatten(0,1)\n",
    "    \n",
    "    KT = K.flatten(1,-1)\n",
    "    \n",
    "    Xprime = Yprime @ KT\n",
    "    Xprime = Xprime.reshape(N, -1, Xprime.shape[-1]).transpose(1,2)\n",
    "    X = fold(Xprime, output_size=[h_out,w_out], kernel_size=h, padding=padding, dilation=dilation, stride=stride)\n",
    "    return X\n",
    "\n",
    "\n",
    "def augment(input, nzeros, padding=0):\n",
    "    shape = input.shape\n",
    "    nold  = shape[-1]\n",
    "    nnew  = nold + (nold-1)*nzeros\n",
    "    \n",
    "    new = torch.zeros(*shape[:2], nnew, nnew)\n",
    "    new[:,:,::(nzeros+1),::(nzeros+1)] = input\n",
    "                \n",
    "    if padding: new = unfold(new,1, padding=padding).reshape(*new.shape[:2],*[new.shape[-1]+2*padding]*2)\n",
    "    return new\n",
    "\n",
    "\n",
    "def weight_backward(input, dL_dy, weight, ignored, stride=1):\n",
    "    dL_df = torch.zeros_like(weight.transpose(0,1))\n",
    "    dL_dy_aug = augment(dL_dy, nzeros=stride-1, padding=0)\n",
    "    \n",
    "    x = input if not ignored else input[:,:,:-ignored, :-ignored]\n",
    "    \n",
    "    for mu in range(x.shape[0]):\n",
    "        for alpha in range(x.shape[1]):\n",
    "            dLdy = dL_dy_aug[[mu]].transpose(0,1)\n",
    "            xx   = x[mu,alpha].view(1,1,*x.shape[2:])\n",
    "            dL_df[alpha] += conv2d(xx, dLdy)[0]\n",
    "\n",
    "    dL_df.transpose_(0,1)\n",
    "    return dL_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Conv2d():\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1):\n",
    "        self.in_channels  = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride   = stride\n",
    "        self.padding  = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.weight   = torch.Tensor(out_channels, in_channels, kernel_size, kernel_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return conv2d(input, self.weight, stride=self.stride, padding=self.padding, dilation=self.dilation)\n",
    "    \n",
    "    __call__ = forward\n",
    "    \n",
    "    def backward(self, input, dL_dy):\n",
    "        dL_dx = conv_transpose2d(dL_dy, self.weight, stride=self.stride, padding=self.padding, dilation=self.dilation)\n",
    "        \n",
    "        ignored = int(input.shape[-1]-dL_dx.shape[-1])\n",
    "        if ignored: dL_dx = pad(dL_dx, (0,ignored,0,ignored))\n",
    "            #dL_dx = unfold(dL_dx, 1, padding=ignored).reshape(*dL_dx.shape[:2],*[dL_dx.shape[-1]+2*ignored]*2)\n",
    "            #dL_dx = dL_dx[:,:,ignored:, ignored:]\n",
    "\n",
    "        dL_df = weight_backward(input, dL_dy, self.weight, ignored, stride=self.stride)\n",
    "        return dL_dx, dL_df\n",
    "    \n",
    "    \n",
    "class ConvTranspose2d():\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1):\n",
    "        self.in_channels  = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size  = kernel_size\n",
    "        self.stride   = stride\n",
    "        self.padding  = padding\n",
    "        self.dilation = dilation\n",
    "\n",
    "        self.weight   = torch.Tensor(in_channels, out_channels, kernel_size, kernel_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return conv_transpose2d(input, self.weight, stride=self.stride,\\\n",
    "                                padding=self.padding, dilation=self.dilation)\n",
    "    \n",
    "    __call__ = forward\n",
    "    \n",
    "    def backward(self, input, dL_dy):\n",
    "        p = self.kernel_size-1-self.padding\n",
    "        z = self.stride-1\n",
    "        \n",
    "        eff_input  = augment(input, nzeros=z, padding=p)\n",
    "        eff_weight = self.weight.flip(2,3).transpose(0,1)\n",
    "        dL_dx, dL_df = conv_backward(eff_input, dL_dy, eff_weight, stride=1, padding=0, dilation=1)\n",
    "        \n",
    "        dL_df = dL_df.flip(2,3).transpose(0,1)\n",
    "        return dL_dx[:,:,p:-p:z+1, p:-p:z+1], dL_df\n",
    "    \n",
    "    \n",
    "class Sigmoid(Module):\n",
    "    def __init__(self,*input):\n",
    "        super(Sigmoid,self).__init__()\n",
    "        self.input = None\n",
    "        return \n",
    "\n",
    "    def forward(self,input):\n",
    "        self.input = input\n",
    "        return torch.sigmoid(input)\n",
    "    \n",
    "    __call__ = forward\n",
    "\n",
    "    def backward(self, dL_dy):\n",
    "        x = self.input\n",
    "        dsigma_dx = torch.sigmoid(x)*(1.-torch.sigmoid(x))\n",
    "        return dL_dy*dsigma_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "918e1a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(x,y,decimals=7):\n",
    "    return torch.all(torch.round(torch.abs(x - y), decimals=decimals)==0.).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02bb054",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4df1f302",
   "metadata": {},
   "source": [
    "## Test Forward Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "137cf7fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = torch.load('../train_data.pkl')\n",
    "a = images[0][:10].float()\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "79b7f89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.empty(5,3,3,3)\n",
    "\n",
    "f[0, 0] = torch.tensor([ [ +0., +0., -1. ], [ +0., +1., +0. ], [ -1., +0., +0. ]])\n",
    "f[1, 0] = torch.tensor([ [ +1., +1., +1. ], [ +1., +1., +1. ], [ +1., +1., +1. ]])\n",
    "f[2, 0] = torch.tensor([ [ -1., +0., +1. ], [ -1., +0., +1. ], [ -1., +0., +1. ]])\n",
    "f[3, 0] = torch.tensor([ [ -1., -1., -1. ], [ +0., +0., +0. ], [ +1., +1., +1. ]])\n",
    "f[4, 0] = torch.tensor([ [ +0., -1., +0. ], [ -1., +4., -1. ], [ +0., -1., +0. ]])\n",
    "\n",
    "for j in range(0,5):\n",
    "    for i in range(1,3):\n",
    "        f[j,i] = f[j,0]\n",
    "        \n",
    "f.requires_grad_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c3ce9c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 5, 30, 30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convolution with torch.functionals\n",
    "conv_a = F.conv2d(a, f, stride=1, padding=0, dilation=1)\n",
    "conv_a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4ce0260",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implemented convolution\n",
    "myconv_a = conv2d(a, f, stride=1, padding=0, dilation=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a19311f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(conv_a==myconv_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6844a71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3eb0e0ce",
   "metadata": {},
   "source": [
    "## Test transposed convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d396357",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input, valid_target = torch.load('../val_data.pkl')\n",
    "\n",
    "select=10\n",
    "x      = (valid_input[:select].float()).requires_grad_()\n",
    "xtrue  = (valid_target[:select].float())\n",
    "\n",
    "stride = 2\n",
    "padding= 1\n",
    "dilation=2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e8306e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.empty(5,3,3,3)\n",
    "\n",
    "f[0, 0] = torch.tensor([ [ +0., +0., -1. ], [ +0., +1., +0. ], [ -1., +0., +0. ]])\n",
    "f[1, 0] = torch.tensor([ [ +1., +1., +1. ], [ +1., +1., +1. ], [ +1., +1., +1. ]])\n",
    "f[2, 0] = torch.tensor([ [ -1., +0., +1. ], [ -1., +0., +1. ], [ -1., +0., +1. ]])\n",
    "f[3, 0] = torch.tensor([ [ -1., -1., -1. ], [ +0., +0., +0. ], [ +1., +1., +1. ]])\n",
    "f[4, 0] = torch.tensor([ [ +0., -1., +0. ], [ -1., +4., -1. ], [ +0., -1., +0. ]])\n",
    "\n",
    "for j in range(0,5):\n",
    "    for i in range(1,3):\n",
    "        f[j,i] = f[j,0]\n",
    "        \n",
    "f.requires_grad_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0150c675",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd   = F.conv_transpose2d(x, f.transpose(0,1), stride=stride, padding=padding, dilation=dilation)\n",
    "mydd = conv_transpose2d(x.detach(), f.transpose(0,1), stride=stride, padding=padding, dilation=dilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f95b3e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.all(mydd==dd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a017ee63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "31a127d4",
   "metadata": {},
   "source": [
    "## Test derivative MSE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15d4f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dL(y,ytrue):\n",
    "    return 2 * (y-ytrue) / y.shape.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "597419a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_input, valid_target = torch.load('../val_data.pkl')\n",
    "\n",
    "select=10\n",
    "y     = (valid_input[:select].double()/255.).requires_grad_()\n",
    "ytrue = (valid_target[:select].double()/255.).requires_grad_()\n",
    "\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c6e1640",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = F.mse_loss(y, ytrue)\n",
    "dL_dy = torch.autograd.grad(L, (y))[0]\n",
    "\n",
    "mydL_dy = dL(y,ytrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "35b93028",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_dy, mydL_dy, decimals=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a6d184",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae211a83",
   "metadata": {},
   "source": [
    "## Test backward Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1c0dfccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input, valid_target = torch.load('../val_data.pkl')\n",
    "\n",
    "select=10\n",
    "x     = (valid_input[:select].float()).requires_grad_()\n",
    "xtrue = (valid_target[:select].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1edaa964",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.empty(5,3,3,3)\n",
    "\n",
    "f[0, 0] = torch.tensor([ [ +0., +0., -1. ], [ +0., +1., +0. ], [ -1., +0., +0. ]])\n",
    "f[1, 0] = torch.tensor([ [ +1., +1., +1. ], [ +1., +1., +1. ], [ +1., +1., +1. ]])\n",
    "f[2, 0] = torch.tensor([ [ -1., +0., +1. ], [ -1., +0., +1. ], [ -1., +0., +1. ]])\n",
    "f[3, 0] = torch.tensor([ [ -1., -1., -1. ], [ +0., +0., +0. ], [ +1., +1., +1. ]])\n",
    "f[4, 0] = torch.tensor([ [ +0., -1., +0. ], [ -1., +4., -1. ], [ +0., -1., +0. ]])\n",
    "\n",
    "for j in range(0,5):\n",
    "    for i in range(1,3):\n",
    "        f[j,i] = f[j,0]\n",
    "        \n",
    "f.requires_grad_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1d6c0c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "x : \t (10, 3, 32, 32)\n",
      "y : \t (10, 5, 30, 30)\n",
      "f : \t (5, 3, 3, 3)\n",
      "dL_dy :  (10, 5, 30, 30)\n",
      "dL_dx :  (10, 3, 32, 32)\n",
      "dL_df :  (5, 3, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "stride = 1\n",
    "y = F.conv2d(x, f, stride=stride)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ytrue = F.conv2d(xtrue, f, stride=stride)\n",
    "\n",
    "L = F.mse_loss(y,ytrue)\n",
    "dL_dy, dL_dx, dL_df = torch.autograd.grad(L, (y,x,f))\n",
    "\n",
    "print(\"Shapes\")\n",
    "print(\"x : \\t\", tuple(x.shape))\n",
    "print(\"y : \\t\", tuple(y.shape))\n",
    "print(\"f : \\t\", tuple(f.shape))\n",
    "print(\"dL_dy : \", tuple(dL_dy.shape))\n",
    "print(\"dL_dx : \", tuple(dL_dx.shape))\n",
    "print(\"dL_df : \", tuple(dL_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "39b5de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "myconv = Conv2d(3 ,5, 3, stride=stride, padding=0, dilation=1)\n",
    "myconv.weight = f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ed976f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "mydL_dx :  torch.Size([10, 3, 32, 32])\n",
      "mydL_df :  torch.Size([5, 3, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "mydL_dx, mydL_df = myconv.backward(x, dL_dy)\n",
    "\n",
    "print(\"Shapes\")\n",
    "print(\"mydL_dx : \",mydL_dx.shape)\n",
    "print(\"mydL_df : \",mydL_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "db7fea0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_dx, mydL_dx, decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "006dd24d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_df, mydL_df, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f409f360",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5bef9e2f",
   "metadata": {},
   "source": [
    "## Test transposed convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "79255d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "dd   = F.conv_transpose2d(x, f.transpose(0,1), stride=2, padding=0)\n",
    "mydd =   conv_transpose2d(x, f.transpose(0,1), stride=2, padding=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae8e8a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dd,mydd,decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b71000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74c084c5",
   "metadata": {},
   "source": [
    "## Test backward Transposed Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d625388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input, valid_target = torch.load('../val_data.pkl')\n",
    "\n",
    "select=10\n",
    "x     = (valid_input[:select].float()).requires_grad_()\n",
    "xtrue = (valid_target[:select].float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5a0c0ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.empty(5,3,3,3)\n",
    "\n",
    "f[0, 0] = torch.tensor([ [ +0., +0., -1. ], [ +0., +1., +0. ], [ -1., +0., +0. ]])\n",
    "f[1, 0] = torch.tensor([ [ +1., +1., +1. ], [ +1., +1., +1. ], [ +1., +1., +1. ]])\n",
    "f[2, 0] = torch.tensor([ [ -1., +0., +1. ], [ -1., +0., +1. ], [ -1., +0., +1. ]])\n",
    "f[3, 0] = torch.tensor([ [ -1., -1., -1. ], [ +0., +0., +0. ], [ +1., +1., +1. ]])\n",
    "f[4, 0] = torch.tensor([ [ +0., -1., +0. ], [ -1., +4., -1. ], [ +0., -1., +0. ]])\n",
    "\n",
    "for j in range(0,5):\n",
    "    for i in range(1,3):\n",
    "        f[j,i] = f[j,0]\n",
    "\n",
    "ff = f.transpose(0,1)\n",
    "ff.requires_grad_();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f077c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "x : \t (10, 3, 32, 32)\n",
      "y : \t (10, 5, 65, 65)\n",
      "f : \t (5, 3, 3, 3)\n",
      "dL_dy :  (10, 5, 65, 65)\n",
      "dL_dx :  (10, 3, 32, 32)\n",
      "dL_df :  (3, 5, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "stride = 2\n",
    "y = F.conv_transpose2d(x, ff, stride=stride)\n",
    "\n",
    "with torch.no_grad():\n",
    "    ytrue = F.conv_transpose2d(xtrue, ff, stride=stride)\n",
    "\n",
    "L = F.mse_loss(y,ytrue)\n",
    "dL_dy, dL_dx, dL_df = torch.autograd.grad(L, (y,x,ff))\n",
    "\n",
    "print(\"Shapes\")\n",
    "print(\"x : \\t\", tuple(x.shape))\n",
    "print(\"y : \\t\", tuple(y.shape))\n",
    "print(\"f : \\t\", tuple(f.shape))\n",
    "print(\"dL_dy : \", tuple(dL_dy.shape))\n",
    "print(\"dL_dx : \", tuple(dL_dx.shape))\n",
    "print(\"dL_df : \", tuple(dL_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbdbef0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7f696e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytconv = ConvTranspose2d(3 ,5, 3, stride=stride, padding=0, dilation=1)\n",
    "mytconv.weight = ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55fc0a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "mydL_dx :  torch.Size([10, 3, 32, 32])\n",
      "mydL_df :  torch.Size([3, 5, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "mydL_dx, mydL_df = mytconv.backward(x, dL_dy)\n",
    "\n",
    "print(\"Shapes\")\n",
    "print(\"mydL_dx : \",mydL_dx.shape)\n",
    "print(\"mydL_df : \",mydL_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5dcaaf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_dx, mydL_dx, decimals=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0022c508",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_df, mydL_df, decimals=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755107c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f66f2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c10bbb47",
   "metadata": {},
   "source": [
    "## Test Sigmoid backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "edecc891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "x : \t (10, 3, 32, 32)\n",
      "y : \t (10, 3, 32, 32)\n",
      "dL_dy :  (10, 3, 32, 32)\n",
      "dL_dx :  (10, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "select= 10\n",
    "x     = (valid_input[:select].float()).requires_grad_()\n",
    "xtrue = (valid_target[:select].float())\n",
    "\n",
    "y     = torch.sigmoid(x)\n",
    "ytrue = torch.sigmoid(xtrue)\n",
    "\n",
    "L = F.mse_loss(y, ytrue)\n",
    "dL_dy, dL_dx = torch.autograd.grad(L, (y,x))\n",
    "\n",
    "\n",
    "print(\"Shapes\")\n",
    "print(\"x : \\t\", tuple(x.shape))\n",
    "print(\"y : \\t\", tuple(y.shape))\n",
    "print(\"dL_dy : \", tuple(dL_dy.shape))\n",
    "print(\"dL_dx : \", tuple(dL_dx.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "488651f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "myy :  \t  (10, 3, 32, 32)\n",
      "mydL_dx : (10, 3, 32, 32)\n"
     ]
    }
   ],
   "source": [
    "mysig   = Sigmoid()\n",
    "myy     = mysig(x)\n",
    "mydL_dx = mysig.backward(dL_dy)\n",
    "\n",
    "print(\"Shapes\")\n",
    "print(\"myy :  \\t \", tuple(myy.shape))\n",
    "print(\"mydL_dx :\" , tuple(mydL_dx.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "32060ef3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_dx, mydL_dx, decimals=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1835fdab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eba5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2daa11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89df4259",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e746b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ea45478",
   "metadata": {},
   "source": [
    "## Test TransverseConv2d + Sigmoid backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d69b992e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE FILTER\n",
    "f = torch.empty(5,3,3,3)\n",
    "\n",
    "f[0, 0] = torch.tensor([ [ +0., +0., -1. ], [ +0., +1., +0. ], [ -1., +0., +0. ]])\n",
    "f[1, 0] = torch.tensor([ [ +1., +1., +1. ], [ +1., +1., +1. ], [ +1., +1., +1. ]])\n",
    "f[2, 0] = torch.tensor([ [ -1., +0., +1. ], [ -1., +0., +1. ], [ -1., +0., +1. ]])\n",
    "f[3, 0] = torch.tensor([ [ -1., -1., -1. ], [ +0., +0., +0. ], [ +1., +1., +1. ]])\n",
    "f[4, 0] = torch.tensor([ [ +0., -1., +0. ], [ -1., +4., -1. ], [ +0., -1., +0. ]])\n",
    "\n",
    "for j in range(0,5):\n",
    "    for i in range(1,3):\n",
    "        f[j,i] = f[j,0]\n",
    "        \n",
    "ff = f.transpose(0,1)\n",
    "ff.requires_grad_()\n",
    "\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c87d0baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "x0 : \t (10, 3, 32, 32)\n",
      "y0=x1 :  (10, 5, 65, 65)\n",
      "y1 : \t (10, 5, 65, 65)\n",
      "f  : \t (3, 5, 3, 3) \n",
      "\n",
      "dL_dy1 : (10, 5, 65, 65)\n",
      "dL_dy0 : (10, 5, 65, 65)\n",
      "dL_dx0 : (10, 3, 32, 32)\n",
      "dL_df  : (3, 5, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "#DEFINE DERIVATIVES WITH AUTOGRAD\n",
    "select= 10\n",
    "x0    = (valid_input[:select].float()).requires_grad_()\n",
    "xtrue = (valid_target[:select].float())\n",
    "\n",
    "y0 = F.conv_transpose2d(x0, ff, stride=stride)\n",
    "y1 = torch.sigmoid(y0)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    ytrue = F.conv_transpose2d(xtrue, ff, stride=stride)\n",
    "    ytrue = torch.sigmoid(ytrue)\n",
    "    \n",
    "L = F.mse_loss(y1,ytrue)\n",
    "\n",
    "dL_dy1, dL_dy0, dL_dx0, dL_df = torch.autograd.grad(L, (y1, y0, x0, ff))\n",
    "\n",
    "print(\"Shapes\")\n",
    "print(\"x0 : \\t\", tuple(x0.shape))\n",
    "print(\"y0=x1 : \", tuple(y0.shape))\n",
    "print(\"y1 : \\t\", tuple(y1.shape))\n",
    "print(\"f  : \\t\", tuple(ff.shape),\"\\n\")\n",
    "print(\"dL_dy1 :\", tuple(dL_dy0.shape))\n",
    "print(\"dL_dy0 :\", tuple(dL_dy1.shape))\n",
    "print(\"dL_dx0 :\", tuple(dL_dx0.shape))\n",
    "print(\"dL_df  :\", tuple(dL_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70952163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52a14235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes\n",
      "mydL_dy0 : (10, 5, 65, 65)\n",
      "mydL_dx0 : (10, 3, 32, 32)\n",
      "mydL_df  : (3, 5, 3, 3)\n"
     ]
    }
   ],
   "source": [
    "#DEFINE DERIVATIVES WO AUTOGRAD\n",
    "mytconv = ConvTranspose2d(3 ,5, 3, stride=stride, padding=0, dilation=1)\n",
    "mytconv.weight = ff\n",
    "\n",
    "mysig = Sigmoid()\n",
    "\n",
    "myy0 = mytconv(x0)\n",
    "myy1 = mysig(myy0)\n",
    "\n",
    "mydL_dy0 = mysig.backward(dL_dy1)\n",
    "mydL_dx0, mydL_df = mytconv.backward(x0, mydL_dy0)\n",
    "\n",
    "print(\"Shapes\")\n",
    "print(\"mydL_dy0 :\", tuple(mydL_dy0.shape))\n",
    "print(\"mydL_dx0 :\", tuple(mydL_dx0.shape))\n",
    "print(\"mydL_df  :\", tuple(mydL_df.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35608a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_dx0, mydL_dx0, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0b57b049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_dy0, mydL_dy0, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1aa0dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare(dL_df, mydL_df, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ad66e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86ee805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37004078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
