{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd21fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fda357d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_dataset(dataset):\n",
    "    for d in dataset:\n",
    "        mean = d.mean([-1,-2])\n",
    "        std  = d.std([-1,-2])\n",
    "        norm = torchvision.transforms.Normalize(mean, std, inplace=True)\n",
    "        norm(d)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfafba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        oute = 64       # nb of channels in encoding layers\n",
    "        outd = 2*oute   # nb ofchannels in middle decoding layers\n",
    "        ChIm = 3        # input's nb of channels\n",
    "        kers = 3        # fixed kernel size for all convolutional layers\n",
    "        nb_elayers = 3  # number of encoding layers \n",
    "            \n",
    "        #ENCODER\n",
    "        self.conv0 = nn.Conv2d(in_channels=ChIm, out_channels=oute, kernel_size=kers, padding='same')\n",
    "        self.conv1 = nn.Conv2d(in_channels=oute, out_channels=oute, kernel_size=kers, padding='same')\n",
    "        eblock = self._Encoder_Block(in_channles=oute, out_channels=oute, conv_ksize=kers, maxp_ksize=2)\n",
    "        self.eblocks = nn.ModuleList([eblock]*nb_elayers)\n",
    "        \n",
    "        #DECODER\n",
    "        dblock0 = self._Decoder_Block(in0=2*oute, in1=outd, out1=outd, conv_ksize=kers)\n",
    "        dblock1 = self._Decoder_Block(in0=outd+oute, in1=outd, out1=outd, conv_ksize=kers)\n",
    "        dblock2 = self._Decoder_Block(in0=outd+ChIm, in1=outd//2, out1=outd//3, conv_ksize=kers)\n",
    "        self.dblocks = nn.ModuleList([dblock0] + [dblock1]*(nb_elayers-2) + [dblock2])\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=outd//3, out_channels=ChIm, kernel_size=kers, padding='same')\n",
    "\n",
    "    class _Encoder_Block(nn.Module):\n",
    "        \n",
    "        def __init__(self, in_channles, out_channels, conv_ksize, maxp_ksize):\n",
    "            super().__init__()\n",
    "            self.conv = nn.Conv2d(in_channels=in_channles, out_channels=out_channels,\\\n",
    "                                   kernel_size=conv_ksize, padding = 'same')\n",
    "\n",
    "            self.maxp = nn.MaxPool2d(kernel_size=maxp_ksize)\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = F.leaky_relu(self.conv(x)) #convolution\n",
    "            x = self.maxp(x) #pooling\n",
    "            return x\n",
    "    \n",
    "    \n",
    "    class _Decoder_Block(nn.Module):\n",
    "        \n",
    "        def __init__(self, in0, in1, out1, conv_ksize):\n",
    "            super().__init__()\n",
    "            self.conv0 = nn.Conv2d(in_channels=in0, out_channels=in1 , kernel_size=conv_ksize, padding='same')\n",
    "            self.conv1 = nn.Conv2d(in_channels=in1, out_channels=out1, kernel_size=conv_ksize, padding='same')\n",
    "\n",
    "        def forward(self, x, y):\n",
    "            x = F.interpolate(x, scale_factor=2, mode='nearest') #upsample\n",
    "            x = torch.cat((x,y),dim=1) #concatenate\n",
    "            x = F.leaky_relu(self.conv0(x)) #first convolution \n",
    "            x = F.leaky_relu(self.conv1(x)) #second convlution\n",
    "            return x\n",
    "    \n",
    "        \n",
    "    def forward(self, x):\n",
    "        #ENCODER\n",
    "        pout = [x]\n",
    "        y = self.conv0(x)\n",
    "        for l in (self.eblocks[:-1]):\n",
    "            y = l(y)\n",
    "            pout.append(y)\n",
    "        y = self.eblocks[-1](y)\n",
    "        y = self.conv1(y)\n",
    "        \n",
    "        #DECODER\n",
    "        for i,l in enumerate(self.dblocks):\n",
    "            y = l(y, pout[-(i+1)])\n",
    "        y = self.conv2(y)\n",
    "        \n",
    "        return y#y3\n",
    "    \n",
    "    \n",
    "#y  = self.conv0(x)\n",
    "#y1 = self.eblocks[0](y)\n",
    "#y2 = self.eblocks[1](y1)\n",
    "#y3 = self.eblocks[2](y2)\n",
    "#self.conv1(y3)\n",
    "#\n",
    "#y3 = self.dblocks[0](y3, y2)\n",
    "#y3 = self.dblocks[1](y3, y1)\n",
    "#y3 = self.dblocks[2](y3, x)\n",
    "#y3 = self.conv2(y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8332d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def traininig_step(model, criterion, optimizer, train_input, train_target, batch_size):\n",
    "    model.train()\n",
    "    for inputs, targets in zip(train_input.split(batch_size), train_target.split(batch_size)):\n",
    "        output = model(inputs)\n",
    "        loss = criterion(output, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss\n",
    "\n",
    "\n",
    "def validate(model, criterion, val_input, val_target, batch_size):\n",
    "    model.eval()\n",
    "    with torch.no_grad():          \n",
    "        denoised = model(val_input)\n",
    "        denoised = denoised/denoised.max()\n",
    "\n",
    "        ground_truth = val_target\n",
    "        ground_truth = ground_truth/ground_truth.max()\n",
    "\n",
    "        mse = criterion(denoised, ground_truth).item()\n",
    "        psnr = -10 * np.log10(mse + 10**-8)\n",
    "    return mse, psnr\n",
    "\n",
    "\n",
    "def training_protocol(nb_epochs, model, criterion, train_input, train_target, val_input, val_target, batch_size):\n",
    "    #optimizer  = torch.optim.Adam(model.parameters(), lr=5e-4)\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "    \n",
    "    print(\"Epoch:\\t Tr_Err:\\t  PSNR[dB]:\")\n",
    "    for epoch in range(nb_epochs):\n",
    "        loss = traininig_step(model, criterion, optimizer, train_input, train_target, batch_size)\n",
    "        mse, psnr = validate(model, criterion, val_input, val_target, batch_size) \n",
    "        scheduler.step(mse)\n",
    "        print(\"%d\\t %.3f\\t  %.3f\"%(epoch, loss, psnr))\n",
    "            \n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7748e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235613e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c03022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd08dda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_input, valid_target = torch.load('val_data.pkl') #validation set (noise-clean)\n",
    "train_input, train_target = torch.load('train_data.pkl') #test set (noise-noise)\n",
    "\n",
    "train_in = normalize_dataset(train_input.float())\n",
    "train_tg = normalize_dataset(train_target.float())\n",
    "\n",
    "print(\"Vector shape: \",train_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28dc304",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,2, figsize=(8,8))\n",
    "select = 666\n",
    "\n",
    "ax[0,0].imshow(train_input[select].permute(1,2,0), origin='upper')\n",
    "ax[0,1].imshow(train_target[select].permute(1,2,0), origin='upper')\n",
    "ax[0,0].set_title(\"Training input (noisy)\")\n",
    "ax[0,1].set_title(\"Training target (noisy)\")\n",
    "\n",
    "\n",
    "ax[1,0].imshow(valid_input[select].permute(1,2,0), origin='upper')\n",
    "ax[1,1].imshow(valid_target[select].permute(1,2,0), origin='upper')\n",
    "ax[1,0].set_title(\"Validation input (noisy)\")\n",
    "ax[1,1].set_title(\"Validation target (clean)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004543d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8613c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model, criterion = autoencoder().to_device(), nn.MSELoss()\n",
    "\n",
    "batch_size = 500\n",
    "nb_epochs  = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58d4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "training_protocol(nb_epochs, model, criterion, train_in, train_tg, \\\n",
    "                  valid_input.float(), valid_target.float(), batch_size)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94101941",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb35efd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "denoised = model(valid_input.float()).detach()\n",
    "denoised = denoised/denoised.max()\n",
    "ground_truth = valid_target.float()\n",
    "ground_truth = ground_truth/ground_truth.max()\n",
    "noisy = valid_input.float()\n",
    "noisy = noisy/noisy.max()\n",
    "\n",
    "mse = criterion(denoised, ground_truth).item()\n",
    "-10 * np.log10(mse + 10**-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e743a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,3, figsize=(15,12))\n",
    "select = 164\n",
    "\n",
    "ax[0].imshow(noisy[select].permute(1,2,0), origin='upper')\n",
    "ax[1].imshow(denoised[select].permute(1,2,0), origin='upper')\n",
    "ax[2].imshow(ground_truth[select].permute(1,2,0), origin='upper')\n",
    "\n",
    "ax[0].set_title(\"Validation input (noisy)\")\n",
    "ax[1].set_title(\"Denoised input)\")\n",
    "ax[2].set_title(\"Validation target (clean)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0276663e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b699e27c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e804a42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1911e90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
